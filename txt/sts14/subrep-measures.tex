\subsection{Sublexical feature representations}
\label{subrep-features}

We have created a set of similarity measures based on induced representations of character n-grams. The measures are based on similarity between document vectors, here the centroid of the individual term vector representations, which are trained on character n-grams rather than full words. The vector representation are induced in an unsupervised manner from large unannotated corpora using word clustering, topic learning and word representation learning methods.

In this paper,  three different  methods have been used for creating the character n-gram feature representations: 
Brown Clusters \cite{brown1992class}, Latent Semantic Indexing (LSI) topics \cite{deerwester1990indexing}, 
and log linear skip-gram models \cite{mikolov2013efficient}.
The Brown clusters were trained using the implementation by \newcite{liang2005semi}, while the LSI topic vectors and log linear skip-gram representations were trained using the Gensim topic modelling framework \cite{gensim_lrec}. 
In addition, {\em tf-idf\/} (Term-Frequency Inverse Document Frequency) weighting was used when training LSI topic models. 
We used a cosine distance measure between document vectors consisting of the centroid of the term representation vectors. 
For Brown clusters, the normalized term frequency vectors were used with the cluster ids instead of the terms themselves. 
For LSI topic representations, the {\em tf-idf\/} weighted topic mixture for each term was used as the term representation. 
For the log linear skip-grams, the word representations were extracted from the model weight matrix.

%%% Local Variables:  
%%% mode: latex 
%%% TeX-master: "sts14-ntnu" 
%%% End: 